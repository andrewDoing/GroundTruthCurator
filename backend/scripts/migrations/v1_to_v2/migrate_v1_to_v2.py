#!/usr/bin/env python3
"""Migration script for schema v1 to v2: converting legacy 'tags' field to 'manualTags' and 'computedTags'.

This script migrates existing ground truth documents from schema v1 (single 'tags' field)
to schema v2 with separate 'manualTags' and 'computedTags' fields.

This is a standalone script that connects directly to Cosmos DB without depending on
the application's repository layer.

Schema Changes (v1 -> v2):
- v1: Single 'tags' field containing all tags (manual and computed mixed together)
- v2: Separate 'manualTags' (user-provided) and 'computedTags' (auto-generated by plugins)

Migration Logic:
1. For each ground truth document:
   a. If schemaVersion is already 'v2', skip (already migrated)
   b. Move existing 'tags' to 'manualTags'
   c. Compute 'computedTags' using the tag plugin registry
   d. Strip any computed tag values from 'manualTags' (prevent duplicates)
   e. Remove the legacy 'tags' field
   f. Set schemaVersion to 'v2'
   g. Upsert the updated document

Configuration:
    This script loads configuration from migrate_v1_to_v2.env file in the scripts/ directory.
    Copy migrate_v1_to_v2.sample.env to migrate_v1_to_v2.env and configure:

    GTC_COSMOS_ENDPOINT: Cosmos DB endpoint URL
    GTC_COSMOS_DB_NAME: Database name (default: gt-curator)
    GTC_COSMOS_CONTAINER_GT: Container name (default: ground_truth)
    GTC_USE_COSMOS_EMULATOR: Set to 'true' for emulator (uses emulator key, disables SSL verification)

Usage:
    # Dry run (no changes made):
    python scripts/migrate_v1_to_v2.py --dry-run

    # Run migration:
    python scripts/migrate_v1_to_v2.py

    # Migrate specific dataset:
    python scripts/migrate_v1_to_v2.py --dataset my-dataset

    # Verbose output:
    python scripts/migrate_v1_to_v2.py --verbose
"""

from __future__ import annotations

import argparse
import asyncio
import logging
import os
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

from azure.cosmos.aio import CosmosClient
from azure.identity.aio import DefaultAzureCredential
from dotenv import load_dotenv

# Add parent directory to path for imports (needed for plugin registry)
sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent.parent))

from app.plugins import get_default_registry
from app.domain.models import GroundTruthItem


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# Well-known Cosmos DB emulator key
COSMOS_EMULATOR_KEY = (
    "C2y6yDjf5/R+ob0N8A7Cgv30VRDJIWEHLM+4QDU5DE2nQ9nDuVTqobD4b8mGGyPMbIZnqyMsEcaGQy67XIw/Jw=="
)


def load_env_file() -> None:
    """Load configuration from migrate_v1_to_v2.env file."""
    script_dir = Path(__file__).resolve().parent
    env_file = script_dir / "migrate_v1_to_v2.env"

    if not env_file.exists():
        logger.warning(f"Configuration file not found: {env_file}")
        logger.warning("Please create migrate_v1_to_v2.env based on migrate_v1_to_v2.sample.env")
        raise FileNotFoundError(f"Required configuration file not found: {env_file}")

    load_dotenv(env_file)
    logger.info(f"Loaded configuration from {env_file}")


# Configuration from environment
def get_config() -> dict[str, Any]:
    """Load configuration from environment variables."""
    return {
        "endpoint": os.environ.get("GTC_COSMOS_ENDPOINT"),
        "db_name": os.environ.get("GTC_COSMOS_DB_NAME", "gt-curator"),
        "container_name": os.environ.get("GTC_COSMOS_CONTAINER_GT", "ground_truth"),
        "use_emulator": os.environ.get("GTC_USE_COSMOS_EMULATOR", "").lower() == "true",
    }


async def create_cosmos_client(config: dict[str, Any]) -> CosmosClient:
    """Create and return a Cosmos DB client.

    Uses DefaultAzureCredential for production, or the well-known emulator key
    when GTC_USE_COSMOS_EMULATOR is set to 'true'.
    """
    endpoint = config["endpoint"]

    if not endpoint:
        raise ValueError("GTC_COSMOS_ENDPOINT environment variable is required")

    if config["use_emulator"]:
        # Use well-known emulator key and disable SSL verification
        logger.info("Using Cosmos DB emulator with well-known key")
        return CosmosClient(
            url=endpoint,
            credential=COSMOS_EMULATOR_KEY,
            connection_verify=False,
        )
    else:
        # Use DefaultAzureCredential for production
        logger.info("Using DefaultAzureCredential for Cosmos DB authentication")
        credential = DefaultAzureCredential()
        return CosmosClient(
            url=endpoint,
            credential=credential,
        )


async def query_raw_documents(
    container: Any,
    dataset: str | None,
) -> list[dict[str, Any]]:
    """Query raw documents from Cosmos DB without model validation.

    This queries documents directly to handle legacy fields that the
    current model doesn't understand (e.g., 'tags' instead of 'manualTags').
    """
    params: list[dict[str, Any]] = []
    where_clause = "WHERE c.docType = 'ground-truth-item'"

    if dataset:
        where_clause += " AND c.datasetName = @dataset"
        params.append({"name": "@dataset", "value": dataset})

    query = f"SELECT * FROM c {where_clause}"

    docs: list[dict[str, Any]] = []
    items = container.query_items(query=query, parameters=params)
    async for doc in items:
        docs.append(doc)
    return docs


# Schema version constants
SCHEMA_VERSION_V1 = "v1"
SCHEMA_VERSION_V2 = "v2"


def needs_migration(doc: dict[str, Any]) -> bool:
    """Determine if a document needs migration from schema v1 to v2.

    A document needs migration if schemaVersion is 'v1' or missing.
    """
    schema_version = doc.get("schemaVersion", SCHEMA_VERSION_V1)
    return schema_version != SCHEMA_VERSION_V2


def create_temp_model_for_compute(doc: dict[str, Any]) -> GroundTruthItem:
    """Create a temporary GroundTruthItem for computing tags.

    We need to create a minimal model instance that the tag plugins
    can use to compute tags.
    """
    # Create a copy with required fields for model validation
    temp_doc = dict(doc)

    # Ensure required fields exist for v2 model validation
    if "manualTags" not in temp_doc:
        temp_doc["manualTags"] = temp_doc.get("tags", []) or []
    if "computedTags" not in temp_doc:
        temp_doc["computedTags"] = []
    if "history" not in temp_doc or temp_doc["history"] is None:
        temp_doc["history"] = []

    return GroundTruthItem.model_validate(temp_doc)


async def migrate_documents(
    dry_run: bool = True,
    dataset: str | None = None,
    verbose: bool = False,
) -> dict[str, int]:
    """Migrate ground truth documents from legacy tags to manualTags/computedTags.

    This function connects directly to Cosmos DB and works with raw documents
    to handle the legacy 'tags' field that is no longer in the application model.

    Args:
        dry_run: If True, don't make any changes, just report what would be done
        dataset: If provided, only migrate documents in this dataset
        verbose: If True, log each document being processed

    Returns:
        A dict with migration statistics
    """
    config = get_config()
    registry = get_default_registry()

    logger.info(f"Tag plugin registry has {len(registry)} plugins registered")
    logger.info(f"Dry run: {dry_run}")
    logger.info(f"Cosmos endpoint: {config['endpoint']}")
    logger.info(f"Database: {config['db_name']}, Container: {config['container_name']}")
    if dataset:
        logger.info(f"Filtering to dataset: {dataset}")

    stats = {
        "total": 0,
        "migrated": 0,
        "skipped_already_migrated": 0,
        "errors": 0,
    }

    client = await create_cosmos_client(config)

    try:
        database = client.get_database_client(config["db_name"])
        container = database.get_container_client(config["container_name"])

        # Query raw documents (without model validation)
        raw_docs = await query_raw_documents(container, dataset)
        stats["total"] = len(raw_docs)
        logger.info(f"Found {len(raw_docs)} ground truth documents")

        for doc in raw_docs:
            doc_id = doc.get("id", "unknown")
            try:
                # Check if migration is needed
                if not needs_migration(doc):
                    stats["skipped_already_migrated"] += 1
                    if verbose:
                        logger.debug(f"Skipping {doc_id}: already migrated")
                    continue

                # Get legacy tags
                legacy_tags: list[str] = doc.get("tags", []) or []
                existing_manual_tags: list[str] = doc.get("manualTags", []) or []

                # Create temporary model for computing tags
                temp_item = create_temp_model_for_compute(doc)

                # Compute tags using the plugin registry
                computed_tags = registry.compute_all(temp_item)
                computed_tags_set = set(computed_tags)

                # Manual tags = legacy tags + existing manual tags, minus any computed tags
                all_manual_candidates = set(legacy_tags) | set(existing_manual_tags)
                new_manual_tags = sorted(all_manual_candidates - computed_tags_set)

                if verbose:
                    current_schema = doc.get("schemaVersion", SCHEMA_VERSION_V1)
                    logger.info(
                        f"Document {doc_id}: "
                        f"schemaVersion={current_schema} -> {SCHEMA_VERSION_V2}, "
                        f"legacy_tags={legacy_tags}, "
                        f"existing_manual_tags={existing_manual_tags}, "
                        f"new_manual_tags={new_manual_tags}, "
                        f"computed_tags={computed_tags}"
                    )

                if not dry_run:
                    # Update the raw document
                    doc["manualTags"] = new_manual_tags
                    doc["computedTags"] = sorted(computed_tags)
                    doc["schemaVersion"] = SCHEMA_VERSION_V2
                    doc["updatedAt"] = datetime.now(timezone.utc).isoformat()

                    # Remove legacy 'tags' field if present
                    if "tags" in doc:
                        del doc["tags"]

                    # Remove 'tags' field from history items (v2 schema change)
                    # History items no longer have their own tags field
                    if "history" in doc and doc["history"]:
                        for history_item in doc["history"]:
                            if "tags" in history_item:
                                del history_item["tags"]

                    # Remove etag to allow unconditional upsert
                    if "_etag" in doc:
                        del doc["_etag"]

                    # Upsert the document
                    await container.upsert_item(doc)

                stats["migrated"] += 1

            except Exception as e:
                stats["errors"] += 1
                logger.error(f"Error migrating document {doc_id}: {e}")
                if verbose:
                    import traceback

                    traceback.print_exc()

    finally:
        # Clean up Cosmos client
        await client.close()

    return stats


async def main() -> None:
    parser = argparse.ArgumentParser(
        description="Migrate ground truth documents from legacy 'tags' to 'manualTags' and 'computedTags'"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Don't make any changes, just report what would be done",
    )
    parser.add_argument(
        "--dataset",
        type=str,
        default=None,
        help="Only migrate documents in this dataset",
    )
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Verbose output",
    )

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Load environment configuration
    try:
        load_env_file()
    except FileNotFoundError as e:
        logger.error(str(e))
        sys.exit(1)

    logger.info("Starting tag migration...")
    start_time = datetime.now(timezone.utc)

    stats = await migrate_documents(
        dry_run=args.dry_run,
        dataset=args.dataset,
        verbose=args.verbose,
    )

    elapsed = datetime.now(timezone.utc) - start_time

    logger.info("=" * 60)
    logger.info("Migration Summary:")
    logger.info(f"  Total documents:           {stats['total']}")
    logger.info(f"  Migrated:                  {stats['migrated']}")
    logger.info(f"  Skipped (already migrated): {stats['skipped_already_migrated']}")
    logger.info(f"  Errors:                    {stats['errors']}")
    logger.info(f"  Elapsed time:              {elapsed}")
    logger.info("=" * 60)

    if args.dry_run:
        logger.info("This was a DRY RUN. No changes were made.")
        logger.info("Run without --dry-run to apply changes.")


if __name__ == "__main__":
    asyncio.run(main())
